---
title: AstroClassifier
emoji: ðŸ”­
colorFrom: blue
colorTo: indigo
sdk: gradio
sdk_version: 5.16.0
app_file: demo/app.py
pinned: false
---

# AstroClassifier

**Deep learning pipeline for galaxy morphology classification â€” 10 classes, trained from scratch on Galaxy10 DECals.**

[![Python](https://img.shields.io/badge/Python-3.13-blue?logo=python)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0-ee4c2c?logo=pytorch)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![HuggingFace](https://img.shields.io/badge/Demo-HuggingFace%20Spaces-yellow?logo=huggingface)](https://huggingface.co/spaces/YOUR_USERNAME/astro-classifier)

---

## Live Demo

**[â†’ Try it on Hugging Face Spaces]()**

Upload any galaxy image and get instant morphology classification with per-class confidence scores.

---

## The Problem

Galaxy morphology classification is a real astrophysics problem â€” the [Galaxy Zoo project](https://www.zooniverse.org/projects/zookeeper/galaxy-zoo/) crowdsourced millions of human classifications because it's hard enough that automation is non-trivial.

Two specific challenges make this interesting from an ML perspective:

**1. Class imbalance** â€” some morphologies are far rarer than others (5.6:1 ratio in this dataset). A naive model that ignores this gets decent accuracy but terrible recall on rare classes.

**2. Visually similar classes** â€” `unbarred_tight_spiral` and `unbarred_loose_spiral` are so similar that even human annotators disagree. This puts a real ceiling on model performance that hyperparameter tuning alone cannot overcome.

---

## Architecture

Custom CNN trained from scratch â€” no pretrained backbone.

```
Input (B, 3, 128, 128)
â†’ ConvBlock(3â†’32)      # Edge detection
â†’ ConvBlock(32â†’64)     # Texture features
â†’ ConvBlock(64â†’128)    # Morphological patterns
â†’ ConvBlock(128â†’256)   # High-level abstractions
â†’ GlobalAvgPool        # Translation invariance
â†’ Classifier(256â†’128â†’10)
```

Each ConvBlock: `Conv2d â†’ BatchNorm â†’ ReLU â†’ MaxPool â†’ Dropout`

**0.42M parameters** â€” deliberately lightweight to demonstrate that architecture and training strategy matter more than scale for this dataset size.

---

## Key Technical Decisions

### Focal Loss (Î³=3.0)
Standard cross-entropy ignores class difficulty. Focal Loss down-weights easy examples so the model is forced to learn from hard/rare ones:

```
FL(pâ‚œ) = -Î±(1 - pâ‚œ)^Î³ Â· log(pâ‚œ)
```

### WeightedRandomSampler
Ensures every batch has ~equal class representation regardless of dataset frequency. Without this, the DataLoader rarely shows rare classes even with Focal Loss.

### GlobalAvgPool instead of Flatten
Celestial objects have no canonical orientation. GlobalAvgPool provides translation invariance and reduces parameter count.

### Macro F1 as primary metric
Accuracy is misleading on imbalanced datasets. Macro F1 treats all classes equally.

---

## Dataset

**[Galaxy10 DECals](https://zenodo.org/records/10845026)** â€” 17,736 galaxy images at 256Ã—256 RGB from the DECam Legacy Survey.

| Class | Train | Val | Test | Total |
|-------|-------|-----|------|-------|
| disturbed | 756 | 162 | 163 | 1,081 |
| merging | 1,297 | 277 | 279 | 1,853 |
| round_smooth | 1,851 | 396 | 398 | 2,645 |
| in_between | 1,418 | 304 | 305 | 2,027 |
| cigar_shaped | 233 | 50 | 51 | **334** |
| barred_spiral | 1,430 | 306 | 307 | 2,043 |
| unbarred_tight_spiral | 1,280 | 274 | 275 | 1,829 |
| unbarred_loose_spiral | 1,839 | 394 | 395 | 2,628 |
| edge_on_no_bulge | 996 | 213 | 214 | 1,423 |
| edge_on_with_bulge | 1,311 | 280 | 282 | 1,873 |
| **Total** | **12,411** | **2,656** | **2,669** | **17,736** |

Imbalance ratio: **5.6:1** (round_smooth vs cigar_shaped)

---

## Experiment Results

Two training runs, one hypothesis: does higher Î³ help with the hard classes?

### Run Comparison

| Metric | Run 1 (Î³=2.0, 50 ep) | Run 2 (Î³=3.0, 75 ep) | Î” |
|--------|----------------------|----------------------|---|
| **Macro F1** | 0.5493 | **0.6069** | +0.058 |
| **Macro AUC** | 0.9211 | **0.9353** | +0.014 |
| **Accuracy** | 58.7% | **64.3%** | +5.6% |

### Per-Class F1 (Run 2 â€” Best Model)

| Class | Precision | Recall | F1 | AUC |
|-------|-----------|--------|----|-----|
| disturbed | 0.286 | 0.399 | 0.333 | 0.796 |
| merging | 0.660 | 0.591 | 0.624 | 0.941 |
| round_smooth | 0.795 | 0.887 | **0.838** | 0.981 |
| in_between | 0.835 | 0.761 | 0.796 | 0.979 |
| cigar_shaped | 0.231 | **0.902** | 0.368 | 0.979 |
| barred_spiral | 0.567 | 0.704 | 0.628 | 0.921 |
| unbarred_tight_spiral | 0.599 | 0.756 | 0.669 | 0.945 |
| unbarred_loose_spiral | 0.640 | 0.139 | 0.229 | 0.854 |
| edge_on_no_bulge | 0.809 | 0.790 | 0.799 | 0.982 |
| edge_on_with_bulge | 0.839 | 0.738 | 0.785 | 0.976 |

### What the results tell us

`cigar_shaped` recall of **0.902** with only 334 training samples is Focal Loss working exactly as intended.

`unbarred_loose_spiral` F1 improved from 0.136 â†’ 0.229 with higher Î³, but remains the weak class. This is a **labelling ambiguity problem** not a modelling problem â€” Galaxy Zoo inter-rater agreement on loose vs tight spirals is historically low. The model has learned a real visual boundary; the ceiling is set by data quality, not architecture.

---

## Project Structure

```
astro-classifier/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ base_config.yaml          # All hyperparameters
â”‚   â””â”€â”€ experiment_focal.yaml     # Run 2 overrides (Î³=3.0, 75 epochs)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py            # AstroDataset, augmentations
â”‚   â”‚   â””â”€â”€ dataloader.py         # WeightedRandomSampler factory
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ astro_cnn.py          # Custom CNN architecture
â”‚   â”‚   â””â”€â”€ model_factory.py      # Model registry
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ losses.py             # FocalLoss implementation
â”‚   â”‚   â”œâ”€â”€ scheduler.py          # Optimizer + LR scheduler
â”‚   â”‚   â””â”€â”€ trainer.py            # Training loop, W&B
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py            # Per-class F1, AUC
â”‚   â”‚   â”œâ”€â”€ evaluator.py          # Full eval pipeline
â”‚   â”‚   â””â”€â”€ visualizer.py         # ROC, PR curves, confusion matrix
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py             # YAML loader with inheritance
â”‚       â”œâ”€â”€ logger.py             # Structured logging
â”‚       â””â”€â”€ checkpointing.py      # Top-k checkpoint management
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ prepare_data.py           # Galaxy10 HDF5 â†’ folder structure
â”‚   â”œâ”€â”€ train.py                  # Training entrypoint
â”‚   â”œâ”€â”€ evaluate.py               # Standalone evaluation
â”‚   â””â”€â”€ infer.py                  # Single image inference
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ app.py                    # Gradio demo (HF Spaces)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_EDA.ipynb              # Exploratory data analysis
â””â”€â”€ tests/
    â”œâ”€â”€ test_dataset.py
    â””â”€â”€ test_losses.py
```

---

## Quickstart

```bash
# 1. Clone and install
git clone https://github.com/rahulgunwanistudy-2005/astro-classifier.git
cd astro-classifier
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# 2. Download dataset (~1.4GB)
mkdir -p data/raw
curl -L -o data/raw/Galaxy10_DECals.h5 \
  https://zenodo.org/records/10845026/files/Galaxy10_DECals.h5

# 3. Prepare data
python scripts/prepare_data.py

# 4. Train Run 1
python scripts/train.py --config configs/base_config.yaml

# 5. Train Run 2
python scripts/train.py --config configs/experiment_focal.yaml

# 6. Evaluate
python scripts/evaluate.py \
  --config configs/experiment_focal.yaml \
  --checkpoint outputs/checkpoints_run2/best_model.pth \
  --output-dir outputs/eval_run2

# 7. Run demo locally
pip install -r requirements-demo.txt
python demo/app.py
```

---

## Tests

```bash
pytest tests/ -v
```

---

## Tech Stack

| Component | Tool |
|-----------|------|
| Framework | PyTorch 2.0 |
| Loss | Focal Loss (custom) |
| Sampling | WeightedRandomSampler |
| Experiment tracking | Weights & Biases |
| Config system | YAML with inheritance |
| Demo | Gradio â†’ HuggingFace Spaces |
| Dataset | Galaxy10 DECals (Zenodo) |